{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course Human-Centered Data Science ([HCDS](https://www.mi.fu-berlin.de/en/inf/groups/hcc/teaching/winter_term_2020_21/course_human_centered_data_science.html)) - Winter Term 2020/21 - [HCC](https://www.mi.fu-berlin.de/en/inf/groups/hcc/index.html) | [Freie Universität Berlin](https://www.fu-berlin.de/)\n",
    "***\n",
    "# A2 - Reproducibility Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your assignment is to create a graph that looks a lot like the one below one, starting from scratch, and following best practices for reproducible research.\n",
    "\n",
    "![wikipedia_pageViews_2008-2020.png](img/wikipedia_pageViews_2008-2020.png)\n",
    "\n",
    "## Before you start\n",
    "1. Read all instructions carefully before you begin.\n",
    "1. Read all API documentation carefully before you begin.\n",
    "1. Experiment with queries in the sandbox of the technical documentation for each API to familiarize yourself with the schema and the data.\n",
    "1. Ask questions if you are unsure about anything!\n",
    "1. When documenting your project, please keep the following questions in your mind:\n",
    "   * _If I found this GitHub repository, and wanted to fully reproduce the analysis, what information would I want?_\n",
    "   * _What information would I need?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1️⃣: Data acquisition\n",
    "In order to measure Wikipedia traffic from January 2008 until October 2020, you will need to collect data from two different APIs:\n",
    "\n",
    "1. The **Legacy Pagecounts API** ([documentation](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Legacy_Pagecounts), [endpoint](https://wikimedia.org/api/rest_v1/#!/Pagecounts_data_(legacy)/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end)) provides access to desktop and mobile traffic data from December 2007 through July 2016.\n",
    "1. The **Pageviews API** ([documentation](https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews), [endpoint](https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end)) provides access to desktop, mobile web, and mobile app traffic data from July 2015 through last month.\n",
    "\n",
    "For each API, you need to collect data for all months where data is available and then save the raw results into five (3+2) separate `JSON`files (one file per API query type) before continuing to step 2.\n",
    "\n",
    "To get you started, you can use the following **sample code for API calls**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://public.paws.wmcloud.org/User:Jtmorgan/data512_a1_example.ipynb?format=raw\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "endpoint_legacy = 'https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "endpoint_pageviews = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}'\n",
    "\n",
    "# SAMPLE parameters for getting aggregated legacy view data \n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Legacy_data/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end\n",
    "rest_params_legacy_desktop = {\n",
    "    \"project\" : \"en.wikipedia.org\",\n",
    "    \"access-site\" : \"desktop-site\", # mobile-site\n",
    "    \"granularity\" : \"monthly\",\n",
    "    \"start\" : \"2008010100\",\n",
    "    \"end\" : \"2016073123\"\n",
    "}\n",
    "\n",
    "rest_params_legacy_mobile = copy.deepcopy(rest_params_legacy_desktop)\n",
    "rest_params_legacy_mobile[\"access-site\"] = \"mobile-site\"\n",
    "\n",
    "# SAMPLE parameters for getting aggregated current standard pageview data\n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end\n",
    "rest_params_pageviews_desktop = {\n",
    "    \"project\" : \"en.wikipedia.org\",\n",
    "    \"access\" : \"desktop\",\n",
    "    \"agent\" : \"user\",\n",
    "    \"granularity\" : \"monthly\",\n",
    "    \"start\" : \"2015070100\",\n",
    "    \"end\" : '2020110100'\n",
    "}\n",
    "\n",
    "rest_params_pageviews_mobile_web = copy.deepcopy(rest_params_pageviews_desktop)\n",
    "rest_params_pageviews_mobile_app = copy.deepcopy(rest_params_pageviews_desktop)\n",
    "rest_params_pageviews_mobile_web[\"access\"] = \"mobile-web\"\n",
    "rest_params_pageviews_mobile_app[\"access\"] = \"mobile-app\"\n",
    "\n",
    "# Customize these with your own information\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/Arne117',\n",
    "    'From': 'arner92@zedat.fu-berlin.de'\n",
    "}\n",
    "\n",
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    response = call.json()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we retrieve and save the `desktop` and `mobile traffic` data from the legacy pagecounts REST API in two sperate `.json` files. The naming convention for the source data files is: `apiname_accesstype_firstmonth-lastmonth.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_monthly_desktop = api_call(endpoint_legacy, rest_params_legacy_desktop)\n",
    "legacy_monthly_mobile = api_call(endpoint_legacy, rest_params_legacy_mobile)\n",
    "\n",
    "with open('../data_raw/pagecounts_desktop-site_200801-201607.json', 'w') as json_file:\n",
    "    json.dump(legacy_monthly_desktop, json_file)\n",
    "\n",
    "with open('../data_raw/pagecounts_mobile-site_200801-201607.json', 'w') as json_file:\n",
    "    json.dump(legacy_monthly_mobile, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve and save the `desktop`, `mobile-web` and `mobile-app` traffic data from the pageviews REST API in three sperate `.json` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageviews_monthly_desktop = api_call(endpoint_pageviews, rest_params_pageviews_desktop)\n",
    "pageviews_monthly_mobile_web = api_call(endpoint_pageviews, rest_params_pageviews_mobile_web)\n",
    "pageviews_monthly_mobile_app = api_call(endpoint_pageviews, rest_params_pageviews_mobile_app)\n",
    "\n",
    "with open('../data_raw/pageviews_desktop_201507-202010.json', 'w') as json_file:\n",
    "    json.dump(pageviews_monthly_desktop, json_file)\n",
    "\n",
    "with open('../data_raw/pageviews_mobile-web_201507-202010.json', 'w') as json_file:\n",
    "    json.dump(pageviews_monthly_mobile_web, json_file)\n",
    "    \n",
    "with open('../data_raw/pageviews_mobile-app_201507-202010.json', 'w') as json_file:\n",
    "    json.dump(pageviews_monthly_mobile_app, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `JSON`-formatted source data file must contain the complete and un-edited output of your API queries. The naming convention for the source data files is: `apiname_accesstype_firstmonth-lastmonth.json`. For example, your filename for monthly page views on desktop should be: `pagecounts_desktop-site_200712-202010.json`\n",
    "\n",
    "In the end there shoud be: `legacy_desktop, legacy_mobile, pageviews_desktop, pageviews_mobile_app, pageviews_mobile_web`\n",
    "\n",
    "### Important notes❗\n",
    "1. As much as possible, we're interested in *organic* (user) traffic, as opposed to traffic by web crawlers or spiders. The Pageview API (but not the Pagecount API) allows you to filter by `agent=user`. You should do that.\n",
    "1. There is about one year of overlapping traffic data between the two APIs. You need to gather, and later graph, data from both APIs for this period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data processing\n",
    "\n",
    "You will need to perform a series of processing steps on these data files in order to prepare them for analysis. These steps must be followed exactly in order to prepare the data for analysis. At the end of this step, you will have a single `CSV`-formatted data file `en-wikipedia_traffic_200712-202010.csv` that can be used in your analysis (step 3) with no significant additional processing.\n",
    "\n",
    "* For data collected from the Pageviews API, combine the monthly values for `mobile-app` and `mobile-web` to create a total mobile traffic count for each month.\n",
    "* For all data, separate the value of `timestamp` into four-digit year (`YYYY`) and two-digit month (`MM`) and discard values for day and hour (`DDHH`).\n",
    "\n",
    "Combine all data into a single CSV file with the following headers:\n",
    "\n",
    "| year | month |pagecount_all_views|pagecount_desktop_views|pagecount_mobile_views|pageview_all_views|pageview_desktop_views|pageview_mobile_views|\n",
    "|------| ------|-------------------|-----------------------|----------------------|------------------|----------------------|---------------------|\n",
    "| YYYY | MM    |num_views          |num_views              |num_views             |num_views         |num_views             |num_views            | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data processing part we are using the Pandas library. We then convert the data from json into a Pandas data frame. Here we are using the already used vairables from data acquisition part but we could also load the file directly from the `data_raw` folder. Afterwards we define the \"hull\" for the final dataset that we are going to export to a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "legacy_monthly_desktop_df = pd.DataFrame(legacy_monthly_desktop['items'])\n",
    "legacy_monthly_mobile_df = pd.DataFrame(legacy_monthly_mobile['items'])\n",
    "pageviews_monthly_desktop_df = pd.DataFrame(pageviews_monthly_desktop['items'])\n",
    "pageviews_monthly_mobile_web_df = pd.DataFrame(pageviews_monthly_mobile_web['items'])\n",
    "pageviews_monthly_mobile_app_df = pd.DataFrame(pageviews_monthly_mobile_app['items'])\n",
    "\n",
    "final_dataset = pd.DataFrame({\n",
    "  'timestamp': [] # will be removed later\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge the data frames that don't need to be transformed into the final dataset by just renaming the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = pd.merge(final_dataset, legacy_monthly_desktop_df[['timestamp', 'count']], on='timestamp', how='outer').rename(columns={\"count\": \"pagecount_desktop_views\"})\n",
    "final_dataset = pd.merge(final_dataset, legacy_monthly_mobile_df[['timestamp', 'count']], on='timestamp', how='outer').rename(columns={\"count\": \"pagecount_mobile_views\"})\n",
    "final_dataset = pd.merge(final_dataset, pageviews_monthly_desktop_df[['timestamp', 'views']], on='timestamp', how='outer').rename(columns={\"views\": \"pageview_desktop_views\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then combine combine the monthly values for mobile-app and mobile-web to create a total mobile traffic count for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageviews_mobile_df = pd.merge(pageviews_monthly_mobile_web_df[['timestamp', 'views']], pageviews_monthly_mobile_app_df[['timestamp', 'views']], on='timestamp') # .set_index('timestamp').sum(axis=1)\n",
    "pageviews_mobile_df[\"views\"] = pageviews_mobile_df.loc[:, [\"views_x\", \"views_y\"]].sum(axis=1)\n",
    "pageviews_mobile_df = pageviews_mobile_df.drop(columns=['views_x', 'views_y'])\n",
    "final_dataset = pd.merge(final_dataset, pageviews_mobile_df, on='timestamp', how='outer').rename(columns={\"views\": \"pageview_mobile_views\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to calculate the total amount of pageviews and pagecounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['pagecount_all_views'] = final_dataset.iloc[:, 1:3].sum(axis=1)\n",
    "final_dataset['pageview_all_views'] = final_dataset.iloc[:, 3:5].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets change the timestep format to year (YYYY) and month (MM) and remove the `timestamp` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_orig = final_dataset['timestamp'].str.slice(stop=6)\n",
    "final_dataset['year'] = timestamp_orig.str.slice(stop=4)\n",
    "final_dataset['month'] = timestamp_orig.str.slice(start=-2)\n",
    "final_dataset = final_dataset.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearange columns to the wanted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = final_dataset[['year', 'month', 'pagecount_all_views', 'pagecount_desktop_views', 'pagecount_mobile_views', 'pageview_all_views', 'pageview_desktop_views', 'pageview_mobile_views']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we export the dataset to a `.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final data frame to the data_clean folder as a .csv file.\n",
    "final_dataset.to_csv('../data_clean/en-wikipedia_traffic_200801-202010.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analysis\n",
    "\n",
    "For this assignment, the \"analysis\" will be fairly straightforward: you will visualize the dataset you have created as a **time series graph**. Your visualization will track three traffic metrics: mobile traffic, desktop traffic, and all traffic (mobile + desktop). In order to complete the analysis correctly and receive full credit, your graph will need to be the right scale to view the data; all units, axes, and values should be clearly labeled; and the graph should possess a legend and a title. You must also generate a .png or .jpeg formatted image of your final graph.\n",
    "Please graph the data in your notebook, rather than using an external application!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pagecount_all_views</th>\n",
       "      <th>pagecount_desktop_views</th>\n",
       "      <th>pagecount_mobile_views</th>\n",
       "      <th>pageview_all_views</th>\n",
       "      <th>pageview_desktop_views</th>\n",
       "      <th>pageview_mobile_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>4.930903e+09</td>\n",
       "      <td>4.930903e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>4.818394e+09</td>\n",
       "      <td>4.818394e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>4.955406e+09</td>\n",
       "      <td>4.955406e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>5.159162e+09</td>\n",
       "      <td>5.159162e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>5.584691e+09</td>\n",
       "      <td>5.584691e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.295304e+09</td>\n",
       "      <td>2.721329e+09</td>\n",
       "      <td>4.573975e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.448651e+09</td>\n",
       "      <td>2.638936e+09</td>\n",
       "      <td>4.809714e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.416367e+09</td>\n",
       "      <td>2.613058e+09</td>\n",
       "      <td>4.803309e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.154034e+09</td>\n",
       "      <td>2.661784e+09</td>\n",
       "      <td>4.492251e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.778299e+09</td>\n",
       "      <td>3.041724e+09</td>\n",
       "      <td>4.736574e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  pagecount_all_views  pagecount_desktop_views  \\\n",
       "0    2008      1         4.930903e+09             4.930903e+09   \n",
       "1    2008      2         4.818394e+09             4.818394e+09   \n",
       "2    2008      3         4.955406e+09             4.955406e+09   \n",
       "3    2008      4         5.159162e+09             5.159162e+09   \n",
       "4    2008      5         5.584691e+09             5.584691e+09   \n",
       "..    ...    ...                  ...                      ...   \n",
       "149  2020      6         0.000000e+00                      NaN   \n",
       "150  2020      7         0.000000e+00                      NaN   \n",
       "151  2020      8         0.000000e+00                      NaN   \n",
       "152  2020      9         0.000000e+00                      NaN   \n",
       "153  2020     10         0.000000e+00                      NaN   \n",
       "\n",
       "     pagecount_mobile_views  pageview_all_views  pageview_desktop_views  \\\n",
       "0                       NaN        0.000000e+00                     NaN   \n",
       "1                       NaN        0.000000e+00                     NaN   \n",
       "2                       NaN        0.000000e+00                     NaN   \n",
       "3                       NaN        0.000000e+00                     NaN   \n",
       "4                       NaN        0.000000e+00                     NaN   \n",
       "..                      ...                 ...                     ...   \n",
       "149                     NaN        7.295304e+09            2.721329e+09   \n",
       "150                     NaN        7.448651e+09            2.638936e+09   \n",
       "151                     NaN        7.416367e+09            2.613058e+09   \n",
       "152                     NaN        7.154034e+09            2.661784e+09   \n",
       "153                     NaN        7.778299e+09            3.041724e+09   \n",
       "\n",
       "     pageview_mobile_views  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "..                     ...  \n",
       "149           4.573975e+09  \n",
       "150           4.809714e+09  \n",
       "151           4.803309e+09  \n",
       "152           4.492251e+09  \n",
       "153           4.736574e+09  \n",
       "\n",
       "[154 rows x 8 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv('../data_clean/en-wikipedia_traffic_200801-202010.csv')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Credits\n",
    "\n",
    "This exercise is slighty adapted from the course [Human Centered Data Science (Fall 2019)](https://wiki.communitydata.science/Human_Centered_Data_Science_(Fall_2019)) of [Univeristy of Washington](https://www.washington.edu/datasciencemasters/) by [Jonathan T. Morgan](https://wiki.communitydata.science/User:Jtmorgan).\n",
    "\n",
    "Same as the original inventors, we release the notebooks under the [Creative Commons Attribution license (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
